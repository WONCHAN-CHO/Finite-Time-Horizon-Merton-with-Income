# Finite-Horizon Merton with Labor Income (PG-DPO Backward Solver)
![Status](https://img.shields.io/badge/Status-Work_in_Progress-yellow)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![License](https://img.shields.io/badge/License-MIT-green)


Exploratory research code for solving a finite-horizon Merton consumptionâ€“investment problem **with labor income** using a backward **Pontryagin-Guided Direct Policy Optimization (PG-DPO)** routine. The implementation focuses on the income-to-wealth ratio \(z = Y/X\) and learns time- and state-dependent investment \(\pi(t, z)\) and consumption \(\kappa(t, z)\) controls that align with analytic benchmarks.

> **Status:** Research prototype; configurations and APIs may change without notice.

## What the code does
- Runs PG-DPO backward over multiple horizons to learn controls that respect the Pontryagin Maximum Principle.
- Uses analytic infinite-horizon curves as guidance and error baselines for \(\pi\) and \(\kappa\).
- Produces diagnostic plots (error vs. remaining horizon) in `jupyter_income_1asset_backward/`.

## Key components
- **`run_pgdpo_backward`**: main training loop for a single horizon, setting seeds, devices, and all hyperparameters.
- **`PiKappaPolicy`**: neural actor that outputs hedged investment and bounded consumption ratios from state \((\tau, X, Y)\).
- **`LambdaCritic`**: costate critic estimating the value derivative used in PMP terms.
- **Safe utilities**: NaN- and bound-safe helpers for policy inversion, CRRA utility, discount kernels, and simulation.

## Running the experiments
1. Install dependencies (Python 3.8+, PyTorch, NumPy, Matplotlib). Example:
   ```bash
   pip install torch numpy matplotlib
   ```
2. Execute the script (defaults to horizons 5, 10, 20):
   ```bash
   python Infinite_to_finite.py
   ```
   The script logs device selection, per-horizon progress, and an error table for \(\pi\) and \(\kappa\).

## Configuration highlights
- **Discount/market/income settings** and numerical parameters live in the `CFG` dictionary inside `run_pgdpo_backward`.
- **Plotting grid** is controlled by `CFG["plot"]` (bounds and resolution for \(z\) and \(t\)).
- **Analytic anchors** for \(\pi^*(z)\) and \(\kappa^*(z)\) are generated by `build_analytic_curves_example`, using inputs like excess return, income growth, and risk aversion.

## Outputs
- Figures saved under `jupyter_income_1asset_backward/` showing MAE/RMSE of \(\pi\) and \(\kappa\) against remaining horizon.
- Console summary for each \(T_{\max}\) listing first-slice errors to gauge convergence.

## Notes and next steps
- Current code targets a **1-asset, 1-income** setting; extending to higher dimensions will require revisiting network sizes and simulation logic.
- The baseline uses an exponential discount kernel; other kernels can be toggled in the discount configuration block.
